# PLAN: Database Foundation - Tables & Models

**Phase**: 1 - Database Foundation
**Plan**: 1 of 1
**Objective**: Create brand_groups and models tables with SQLAlchemy models and repositories

---

## Context

This is the foundation phase for the pricing algorithm feature. We need to create two new tables in the `public` schema to store LLM-generated pricing data:

1. **brand_groups**: Stores base prices and expected values for Brand×Group combinations (e.g., "Levi's" + "jeans")
2. **models**: Stores model-specific coefficients and expected features (e.g., "Levi's" + "jeans" + "501")

Both tables are in the `public` schema because they contain shared data across all users (not tenant-specific).

**Architecture Context**:
- StoFlow uses Alembic for migrations with multi-tenant support
- Tables in `public` schema are shared across all tenants
- Tables in `user_X` schemas are tenant-specific
- Migration pattern: Create table → Create model → Create repository
- Use bulk insert with `ON CONFLICT` for idempotence

**Key Files to Reference**:
- Migration pattern: `backend/migrations/versions/20260109_0200_unify_action_types.py`
- Model pattern: `backend/models/public/marketplace_action_type.py`
- Repository pattern: Check existing repositories in `backend/repositories/`

---

## Tasks

### Task 1: Create Alembic migration for brand_groups table

Create migration file: `backend/migrations/versions/YYYYMMDD_HHMM_create_brand_groups_table.py`

**Table Schema**:
```sql
CREATE TABLE public.brand_groups (
    id SERIAL PRIMARY KEY,
    brand VARCHAR(100) NOT NULL,
    group_name VARCHAR(50) NOT NULL,
    base_price DECIMAL(10,2) NOT NULL CHECK (base_price >= 5.00 AND base_price <= 500.00),
    expected_origins JSONB DEFAULT '[]'::jsonb NOT NULL,
    expected_decades JSONB DEFAULT '[]'::jsonb NOT NULL,
    expected_trends JSONB DEFAULT '[]'::jsonb NOT NULL,
    condition_sensitivity DECIMAL(3,2) NOT NULL DEFAULT 1.0 CHECK (condition_sensitivity >= 0.5 AND condition_sensitivity <= 1.5),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL,

    CONSTRAINT uq_brand_groups_brand_group UNIQUE (brand, group_name)
);

CREATE INDEX idx_brand_groups_brand ON public.brand_groups(brand);
CREATE INDEX idx_brand_groups_group ON public.brand_groups(group_name);
CREATE INDEX idx_brand_groups_created_at ON public.brand_groups(created_at DESC);
```

**Requirements**:
- Use `text()` for raw SQL execution (StoFlow pattern)
- Check table existence with `IF NOT EXISTS`
- Include both `upgrade()` and `downgrade()` functions
- Idempotent (safe to run multiple times)
- Print confirmation message after creation

**Validation**:
- Migration creates table successfully on empty database
- Migration is idempotent (can run twice without error)
- Downgrade drops table cleanly
- Constraints enforce valid ranges (base_price 5-500€, sensitivity 0.5-1.5)

---

### Task 2: Create Alembic migration for models table

Create migration file: `backend/migrations/versions/YYYYMMDD_HHMM_create_models_table.py`

**Table Schema**:
```sql
CREATE TABLE public.models (
    id SERIAL PRIMARY KEY,
    brand VARCHAR(100) NOT NULL,
    group_name VARCHAR(50) NOT NULL,
    model VARCHAR(100) NOT NULL,
    coefficient DECIMAL(4,2) NOT NULL DEFAULT 1.0 CHECK (coefficient >= 0.5 AND coefficient <= 3.0),
    expected_features JSONB DEFAULT '[]'::jsonb NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP NOT NULL,

    CONSTRAINT uq_models_brand_group_model UNIQUE (brand, group_name, model)
);

CREATE INDEX idx_models_brand ON public.models(brand);
CREATE INDEX idx_models_group ON public.models(group_name);
CREATE INDEX idx_models_brand_group ON public.models(brand, group_name);
CREATE INDEX idx_models_created_at ON public.models(created_at DESC);
```

**Requirements**:
- Separate migration file (one migration = one logical change)
- Same patterns as Task 1 (idempotent, downgrade, etc.)
- Coefficient range: 0.5-3.0 (0.5 = less desirable, 3.0 = collector item)
- Composite index on (brand, group_name) for frequent lookups

**Validation**:
- Migration creates table successfully
- Unique constraint prevents duplicate (brand, group, model) combinations
- Coefficient constraint enforces valid range

---

### Task 3: Create SQLAlchemy model for BrandGroup

Create file: `backend/models/public/brand_group.py`

**Model Definition**:
```python
from datetime import datetime
from decimal import Decimal
from sqlalchemy import Column, Integer, String, DECIMAL, TIMESTAMP, CheckConstraint, Index, JSONB
from sqlalchemy.orm import Mapped, mapped_column
from shared.database import Base

class BrandGroup(Base):
    """
    Brand×Group pricing data generated by LLM.

    Stores base prices and expected values for a specific brand and product group combination.
    Example: Levi's + jeans → base_price=25€, expected_origins=["USA", "Mexico"]
    """
    __tablename__ = "brand_groups"
    __table_args__ = (
        CheckConstraint('base_price >= 5.00 AND base_price <= 500.00', name='ck_brand_groups_base_price'),
        CheckConstraint('condition_sensitivity >= 0.5 AND condition_sensitivity <= 1.5', name='ck_brand_groups_sensitivity'),
        Index('idx_brand_groups_brand', 'brand'),
        Index('idx_brand_groups_group', 'group_name'),
        Index('idx_brand_groups_created_at', 'created_at'),
        {'schema': 'public'}
    )

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    brand: Mapped[str] = mapped_column(String(100), nullable=False)
    group_name: Mapped[str] = mapped_column(String(50), nullable=False)
    base_price: Mapped[Decimal] = mapped_column(DECIMAL(10, 2), nullable=False)
    expected_origins: Mapped[list] = mapped_column(JSONB, nullable=False, default=list)
    expected_decades: Mapped[list] = mapped_column(JSONB, nullable=False, default=list)
    expected_trends: Mapped[list] = mapped_column(JSONB, nullable=False, default=list)
    condition_sensitivity: Mapped[Decimal] = mapped_column(DECIMAL(3, 2), nullable=False, default=Decimal("1.0"))
    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, default=datetime.utcnow)
    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, default=datetime.utcnow, onupdate=datetime.utcnow)

    def __repr__(self):
        return f"<BrandGroup(brand='{self.brand}', group='{self.group_name}', base_price={self.base_price})>"
```

**Requirements**:
- Follow StoFlow SQLAlchemy 2.0 patterns (Mapped, mapped_column)
- Include docstring explaining purpose
- JSONB columns for arrays (expected_origins, expected_decades, expected_trends)
- Decimal for prices (not float)
- Timestamps with timezone
- Proper __repr__ for debugging

**Validation**:
- Model can be imported without errors
- Can create instances with valid data
- JSONB fields serialize/deserialize correctly

---

### Task 4: Create SQLAlchemy model for Model

Create file: `backend/models/public/model.py`

**Model Definition**:
```python
from datetime import datetime
from decimal import Decimal
from sqlalchemy import Column, Integer, String, DECIMAL, TIMESTAMP, CheckConstraint, Index, JSONB
from sqlalchemy.orm import Mapped, mapped_column
from shared.database import Base

class Model(Base):
    """
    Model-specific pricing data generated by LLM.

    Stores coefficient and expected features for a specific model within a brand×group.
    Example: Levi's + jeans + 501 → coefficient=1.4, expected_features=[]
    Example: Levi's + jeans + Big E → coefficient=2.5, expected_features=["selvedge", "chain_stitching"]
    """
    __tablename__ = "models"
    __table_args__ = (
        CheckConstraint('coefficient >= 0.5 AND coefficient <= 3.0', name='ck_models_coefficient'),
        Index('idx_models_brand', 'brand'),
        Index('idx_models_group', 'group_name'),
        Index('idx_models_brand_group', 'brand', 'group_name'),
        Index('idx_models_created_at', 'created_at'),
        {'schema': 'public'}
    )

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    brand: Mapped[str] = mapped_column(String(100), nullable=False)
    group_name: Mapped[str] = mapped_column(String(50), nullable=False)
    model: Mapped[str] = mapped_column(String(100), nullable=False)
    coefficient: Mapped[Decimal] = mapped_column(DECIMAL(4, 2), nullable=False, default=Decimal("1.0"))
    expected_features: Mapped[list] = mapped_column(JSONB, nullable=False, default=list)
    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, default=datetime.utcnow)
    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, default=datetime.utcnow, onupdate=datetime.utcnow)

    def __repr__(self):
        return f"<Model(brand='{self.brand}', group='{self.group_name}', model='{self.model}', coeff={self.coefficient})>"
```

**Requirements**:
- Same patterns as BrandGroup model
- Separate file for clean separation
- Coefficient as Decimal (1.0 = standard, 1.4 = popular, 2.5 = collector)
- JSONB for expected_features array

**Validation**:
- Model imports successfully
- Can create instances with valid coefficient range
- expected_features serializes as JSON array

---

### Task 5: Create BrandGroupRepository

Create file: `backend/repositories/brand_group_repository.py`

**Repository Interface**:
```python
from typing import Optional
from sqlalchemy.orm import Session
from sqlalchemy import select
from models.public.brand_group import BrandGroup

class BrandGroupRepository:
    """Repository for BrandGroup data access."""

    def __init__(self, db: Session):
        self.db = db

    def find_by_brand_and_group(self, brand: str, group: str) -> Optional[BrandGroup]:
        """Find brand group by exact brand and group name match."""
        stmt = select(BrandGroup).where(
            BrandGroup.brand == brand,
            BrandGroup.group_name == group
        )
        return self.db.execute(stmt).scalar_one_or_none()

    def create(self, brand_group: BrandGroup) -> BrandGroup:
        """Create a new brand group entry."""
        self.db.add(brand_group)
        self.db.flush()  # Get ID without committing transaction
        return brand_group

    def get_all(self, limit: int = 100, offset: int = 0) -> list[BrandGroup]:
        """Get all brand groups with pagination."""
        stmt = select(BrandGroup).order_by(BrandGroup.created_at.desc()).limit(limit).offset(offset)
        return list(self.db.execute(stmt).scalars().all())

    def count(self) -> int:
        """Count total brand groups."""
        from sqlalchemy import func
        stmt = select(func.count(BrandGroup.id))
        return self.db.execute(stmt).scalar()
```

**Requirements**:
- Follow repository pattern (no business logic)
- Use SQLAlchemy 2.0 select() syntax
- Return Optional for single lookups
- flush() instead of commit() (let service control transactions)
- Pagination support for listing

**Validation**:
- Can find existing brand group
- Returns None for non-existent brand group
- Create returns object with ID populated
- Pagination works correctly

---

### Task 6: Create ModelRepository

Create file: `backend/repositories/model_repository.py`

**Repository Interface**:
```python
from typing import Optional
from sqlalchemy.orm import Session
from sqlalchemy import select
from models.public.model import Model

class ModelRepository:
    """Repository for Model data access."""

    def __init__(self, db: Session):
        self.db = db

    def find_by_brand_group_model(self, brand: str, group: str, model: str) -> Optional[Model]:
        """Find model by exact brand, group, and model name match."""
        stmt = select(Model).where(
            Model.brand == brand,
            Model.group_name == group,
            Model.model == model
        )
        return self.db.execute(stmt).scalar_one_or_none()

    def find_by_brand_and_group(self, brand: str, group: str) -> list[Model]:
        """Find all models for a brand and group combination."""
        stmt = select(Model).where(
            Model.brand == brand,
            Model.group_name == group
        ).order_by(Model.model)
        return list(self.db.execute(stmt).scalars().all())

    def create(self, model: Model) -> Model:
        """Create a new model entry."""
        self.db.add(model)
        self.db.flush()
        return model

    def get_all(self, limit: int = 100, offset: int = 0) -> list[Model]:
        """Get all models with pagination."""
        stmt = select(Model).order_by(Model.created_at.desc()).limit(limit).offset(offset)
        return list(self.db.execute(stmt).scalars().all())

    def count(self) -> int:
        """Count total models."""
        from sqlalchemy import func
        stmt = select(func.count(Model.id))
        return self.db.execute(stmt).scalar()
```

**Requirements**:
- Same patterns as BrandGroupRepository
- find_by_brand_and_group() for listing all models of a brand×group
- Consistent method naming

**Validation**:
- Can find specific model
- Returns None for non-existent model
- find_by_brand_and_group() returns multiple models
- Pagination works

---

## Verification

### Automated Tests

Run these commands to verify all tasks:

```bash
# Apply migrations
cd ~/StoFlow-add-pricing-algorithm/backend
alembic upgrade head

# Verify tables exist
psql $DATABASE_URL -c "\dt public.brand_groups"
psql $DATABASE_URL -c "\dt public.models"

# Check table structure
psql $DATABASE_URL -c "\d public.brand_groups"
psql $DATABASE_URL -c "\d public.models"

# Test migration rollback
alembic downgrade -1
alembic upgrade head

# Run any existing tests
pytest tests/ -v -k "brand_group or model" || echo "No tests yet - OK for phase 1"
```

### Manual Verification Checklist

- [ ] brand_groups table created in public schema
- [ ] models table created in public schema
- [ ] Both tables have proper indexes
- [ ] Constraints enforce valid ranges (base_price, coefficient, sensitivity)
- [ ] Unique constraints prevent duplicates
- [ ] BrandGroup model imports without errors
- [ ] Model model imports without errors
- [ ] BrandGroupRepository find/create methods work
- [ ] ModelRepository find/create methods work
- [ ] Migrations are reversible (downgrade works)
- [ ] JSONB columns can store arrays

---

## Success Criteria

**Functional**:
- [x] brand_groups table exists in public schema with correct structure
- [x] models table exists in public schema with correct structure
- [x] Both tables have appropriate indexes for performance
- [x] SQLAlchemy models can be imported and instantiated
- [x] Repositories provide clean data access interface

**Technical**:
- [x] Migrations follow StoFlow patterns (idempotent, text(), IF NOT EXISTS)
- [x] Migrations have both upgrade() and downgrade()
- [x] Models use SQLAlchemy 2.0 syntax (Mapped, mapped_column)
- [x] JSONB columns properly configured for array storage
- [x] Decimal types used for prices (not float)
- [x] Timestamps include timezone
- [x] Check constraints enforce valid ranges

**Quality**:
- [x] Code follows backend/CLAUDE.md conventions
- [x] Docstrings explain purpose of models
- [x] Repository methods are focused and simple
- [x] No business logic in repositories (pure data access)

---

## Output Files

**Created**:
- `backend/migrations/versions/YYYYMMDD_HHMM_create_brand_groups_table.py`
- `backend/migrations/versions/YYYYMMDD_HHMM_create_models_table.py`
- `backend/models/public/brand_group.py`
- `backend/models/public/model.py`
- `backend/repositories/brand_group_repository.py`
- `backend/repositories/model_repository.py`

**Modified**: None

---

## Notes

- These tables are in `public` schema because brand/model data is shared across all users
- JSONB columns store arrays as JSON (e.g., `["USA", "Mexico"]` for expected_origins)
- Decimal type is critical for monetary values (avoids floating-point errors)
- Repositories use flush() not commit() - services control transaction boundaries
- No seed data needed yet - LLM will generate data on-demand in Phase 3

---

*Plan created: 2026-01-09*
