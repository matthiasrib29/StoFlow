---
phase: 12-monitoring-optimization
plan: 01
type: execute
domain: backend
---

<objective>
Add task-level monitoring and performance tracking to the marketplace job system.

Purpose: Enable observability for the task orchestration system with execution time logging, failure rate tracking, and configurable alerts.

Output:
- Task execution times logged with structured format
- Task-level stats service extending existing VintedJobStatsService
- Configurable failure rate alerts (>20% threshold)
- Performance profiling for high-volume operations
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-phase.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Prior Phase Summary:**
@.planning/phases/11-data-cleanup-migration/11-01-SUMMARY.md

**Key files to reference:**
@backend/services/vinted/vinted_job_stats_service.py
@backend/services/marketplace/marketplace_job_processor.py
@backend/services/marketplace/marketplace_job_service.py
@backend/models/user/marketplace_task.py
@backend/shared/logging_setup.py

**Tech stack available:**
- SQLAlchemy 2.0 for database access
- Python logging via get_logger()
- Existing VintedJobStatsService pattern for stats

**Established patterns:**
- Stats tracked in `vinted_job_stats` (renamed to `marketplace_job_stats`)
- Rolling average calculation for duration
- Daily aggregation by action type

**Constraining decisions:**
- Phase 8: Stats separated by marketplace (marketplace_job_stats table)
- Phase 1: 1 task = 1 commit pattern for granular tracking
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add task-level execution time logging</name>
  <files>backend/services/marketplace/task_metrics_service.py, backend/services/marketplace/marketplace_job_processor.py</files>
  <action>
Create `TaskMetricsService` in a new file that:
1. Logs task start/end with structured format: `[TaskMetrics] task_id={id} job_id={job_id} type={task_type} status={status} duration_ms={ms}`
2. Provides `log_task_start(task)` and `log_task_complete(task)` methods
3. Calculates duration from task.started_at and task.completed_at

Update MarketplaceJobProcessor to call TaskMetricsService after each task completes. Do NOT modify the existing job-level logging which already works well.

Use get_logger(__name__) following existing patterns. Log at INFO level for normal operations, WARNING for slow tasks (>5000ms).
  </action>
  <verify>
grep -r "TaskMetrics" backend/services/marketplace/ shows new service
grep "log_task" backend/services/marketplace/marketplace_job_processor.py shows integration
  </verify>
  <done>Task execution times logged with structured format, slow task warnings enabled</done>
</task>

<task type="auto">
  <name>Task 2: Extend stats service for task-level metrics</name>
  <files>backend/services/marketplace/task_metrics_service.py, backend/models/user/marketplace_task_stats.py</files>
  <action>
Add to TaskMetricsService:
1. `update_task_stats(task, success)` method that:
   - Tracks daily task counts by task_type (plugin_http, direct_http, db_operation, file_operation)
   - Calculates rolling average duration per task_type
   - Stores in new `marketplace_task_stats` model (similar to vinted_job_stats pattern)

2. Create `MarketplaceTaskStats` model in models/user/:
   - task_type (enum)
   - marketplace (string)
   - date (date)
   - total_tasks, success_count, failure_count
   - avg_duration_ms (integer)
   - created_at, updated_at

3. Add `get_task_stats(days=7)` method to retrieve stats

Follow the exact pattern from VintedJobStatsService for rolling average calculation. Do NOT create a migration file - use raw SQL in the service to create table if not exists (temporary dev approach, migration can be added later).
  </action>
  <verify>
grep "MarketplaceTaskStats" backend/models/user/__init__.py
python -c "from services.marketplace.task_metrics_service import TaskMetricsService; print('Import OK')"
  </verify>
  <done>Task stats model created, stats service tracks task metrics</done>
</task>

<task type="auto">
  <name>Task 3: Add failure rate alerting</name>
  <files>backend/services/marketplace/task_metrics_service.py</files>
  <action>
Add to TaskMetricsService:
1. `check_failure_rate(marketplace=None, threshold=0.2)` method that:
   - Queries last 1 hour of task stats
   - Calculates failure rate = failure_count / total_tasks
   - Returns dict with: is_alerting, failure_rate, total_tasks, threshold

2. `log_failure_alert(marketplace, failure_rate)` method that:
   - Logs at ERROR level: `[ALERT] High task failure rate: {marketplace} {failure_rate:.1%} (threshold: {threshold:.1%})`
   - Only logs if failure_rate > threshold

3. Call `check_failure_rate()` at end of `update_task_stats()` and log alert if needed

The alert is logged only (no email/webhook integration for now). Log at ERROR level so it's easily visible in log aggregation tools.
  </action>
  <verify>
grep "ALERT" backend/services/marketplace/task_metrics_service.py
grep "check_failure_rate" backend/services/marketplace/task_metrics_service.py
  </verify>
  <done>Failure rate alerting implemented with configurable threshold (default 20%)</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from services.marketplace.task_metrics_service import TaskMetricsService"` succeeds
- [ ] `grep -r "TaskMetrics" backend/services/marketplace/` shows service and integration
- [ ] `grep "ALERT" backend/services/marketplace/task_metrics_service.py` shows alerting code
- [ ] No import errors when running backend tests
</verification>

<success_criteria>
- Task execution times logged with structured format
- Task-level stats tracking implemented
- Failure rate alerting with >20% threshold
- All code follows existing patterns (get_logger, rolling average)
- No regressions in existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/12-monitoring-optimization/12-01-SUMMARY.md`:

# Phase 12 Plan 01: Task Monitoring Summary

**[What was built - e.g., "Task metrics service with execution logging and failure alerting"]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `path/to/file.ts` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

[If more plans in this phase: "Ready for 12-02-PLAN.md"]
[If phase complete: "Phase 12 complete - milestone finished"]
</output>
