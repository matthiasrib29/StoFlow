---
phase: 10-testing-documentation
plan: 02
type: execute
---

<objective>
Write integration tests for the complete job + task orchestration flow, including retry scenarios with idempotence and partial failure recovery.

Purpose: Verify that the entire task orchestration system works end-to-end across all layers (handlers → services → database).
Output: Integration test suite covering full job lifecycle and retry scenarios.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-phase.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/04-ebay-handlers-refactoring/04-01-SUMMARY.md
@.planning/phases/05-etsy-handlers-refactoring/05-01-SUMMARY.md
@.planning/phases/07-vinted-handlers-refactoring/07-01-SUMMARY.md

**Tech stack available:**
- pytest with Docker PostgreSQL for integration tests
- FastAPI TestClient for API testing
- SQLAlchemy with multi-tenant schema support

**Established patterns:**
- Handlers delegate to services
- Services perform business logic
- Task orchestration: PENDING → RUNNING → COMPLETED/FAILED
- Idempotence: Tasks check side-effects before executing

**Key architectural decisions:**
- Phase 1: 1 task = 1 commit (granular tracking)
- Phase 1: Skip COMPLETED tasks on retry
- Phase 1: Idempotence prevents duplicate side-effects
- Phases 4-7: All handlers follow delegation pattern

**Testing requirements from roadmap:**
- Integration tests for full job + task flow
- Retry scenario tests (partial failure, skip completed)
- Performance tests (1000+ tasks) - deferred to Phase 12
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write integration tests for job + task orchestration flow</name>
  <files>backend/tests/integration/test_job_orchestration.py</files>
  <action>
Create comprehensive integration test file for the full job lifecycle:

**Test Database Setup:**
- Use pytest fixture with Docker PostgreSQL (or test DB)
- Create test tenant schema (e.g., "test_user_1")
- Apply all Alembic migrations to test schema
- Clean up after tests (drop test schema)

**Test Scenarios:**

1. **test_create_job_with_tasks():**
   - Create a MarketplaceJob (e.g., publish job)
   - Handler creates MarketplaceTasks via task orchestration
   - Verify tasks created with correct step_type, step_order
   - Verify job status = PENDING

2. **test_execute_job_success_flow():**
   - Create job + tasks
   - Execute handler (simulates job execution)
   - Mock external dependencies (WebSocket, APIs)
   - Verify all tasks transition PENDING → RUNNING → COMPLETED
   - Verify job status transitions to COMPLETED
   - Verify timestamps (started_at, completed_at) set correctly

3. **test_job_with_multiple_marketplaces():**
   - Create jobs for all 3 marketplaces (vinted, ebay, etsy)
   - Execute each handler
   - Verify each follows same orchestration pattern
   - Verify stats tracked per marketplace

4. **test_batch_job_progress_tracking():**
   - Create BatchJob with 3 MarketplaceJobs
   - Execute jobs sequentially
   - Verify BatchJob.progress updates: 0% → 33% → 66% → 100%
   - Verify BatchJob.status updates based on job statuses

**What to mock:**
- External APIs (Vinted WebSocket, eBay API, Etsy API)
- File uploads (images)
- Use mock Product data (don't require real products in DB)

**What to test for real:**
- Database writes (MarketplaceJob, MarketplaceTask, BatchJob)
- Status transitions
- Timestamp updates
- Error handling

Create fixtures for:
- `test_db_session`: PostgreSQL test session
- `test_product`: Mock Product object
- `mock_websocket`: Mock WebSocket communication
- `mock_api_client`: Mock API clients (eBay, Etsy)
  </action>
  <verify>pytest backend/tests/integration/test_job_orchestration.py passes all tests, no database errors</verify>
  <done>Integration tests pass, full job lifecycle tested end-to-end for all marketplaces</done>
</task>

<task type="auto">
  <name>Task 2: Write integration tests for retry scenarios</name>
  <files>backend/tests/integration/test_job_retry_scenarios.py</files>
  <action>
Create integration tests for retry logic and idempotence:

**Test Scenarios:**

1. **test_retry_skips_completed_tasks():**
   - Create job with 5 tasks
   - Execute first 3 tasks successfully (status = COMPLETED)
   - Simulate failure on task 4 (status = FAILED)
   - Retry job execution
   - Verify: Tasks 1-3 skipped (not re-executed)
   - Verify: Task 4 re-executed
   - Verify: Task 5 executed for first time
   - Verify: Job completes successfully

2. **test_idempotence_prevents_duplicate_operations():**
   - Create job for product publication
   - Execute job successfully (product published)
   - Mark job as FAILED manually (simulate failure after publish)
   - Retry job
   - Verify: Handler checks if product already published
   - Verify: No duplicate publication attempt
   - Verify: Job marked as COMPLETED (idempotent success)

3. **test_partial_failure_recovery():**
   - Create job with 10 tasks
   - Execute first 7 tasks successfully
   - Simulate external API failure on task 8
   - Verify: Tasks 1-7 remain COMPLETED
   - Verify: Task 8 marked FAILED
   - Verify: Tasks 9-10 not executed
   - Verify: Job status = FAILED
   - Fix external API (mock returns success)
   - Retry job
   - Verify: Only tasks 8-10 execute
   - Verify: Job completes successfully

4. **test_max_retries_exhausted():**
   - Create job with max_retries=3
   - Simulate persistent failure (task always fails)
   - Execute job 3 times
   - Verify: retry_count increments correctly
   - Verify: After 3 retries, job status = FAILED permanently
   - Verify: Error message logged

5. **test_concurrent_job_execution():**
   - Create BatchJob with 3 jobs
   - Execute jobs in parallel (simulate worker pool)
   - Verify: No race conditions on status updates
   - Verify: All jobs complete independently
   - Verify: BatchJob progress accurate

**Database state verification:**
- Query MarketplaceTask table directly to verify status
- Query MarketplaceJob to verify retry_count
- Verify created_at, started_at, completed_at timestamps
- Verify error_message populated on failures

**What to mock:**
- External API failures (return error responses)
- WebSocket disconnections
- Use realistic failure scenarios (timeouts, auth errors)
  </action>
  <verify>pytest backend/tests/integration/test_job_retry_scenarios.py passes all tests, retry logic verified</verify>
  <done>Retry scenarios tested, idempotence verified, partial failure recovery works correctly</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] All integration tests pass (zero failures)
- [ ] Tests cover full job lifecycle (create → execute → complete)
- [ ] Retry scenarios tested (skip completed, idempotence, partial failure)
- [ ] No database state issues (proper cleanup)
- [ ] Tests run in reasonable time (<30 seconds total)
</verification>

<success_criteria>

- Task 1 completed: Job orchestration integration tests pass
- Task 2 completed: Retry scenario tests pass
- All integration tests pass (zero failures)
- Full job lifecycle verified for all marketplaces
- Retry logic proven to work correctly
- Idempotence verified (no duplicate operations)
</success_criteria>

<output>
After completion, create `.planning/phases/10-testing-documentation/10-02-SUMMARY.md`:

# Phase 10-02: Integration Tests Summary

**Comprehensive integration tests for job + task orchestration, verifying full lifecycle and retry scenarios**

## Accomplishments

- X integration tests created for job orchestration
- Y integration tests created for retry scenarios
- Full job lifecycle tested end-to-end
- Retry logic verified (skip completed, idempotence)
- Partial failure recovery proven

## Files Created/Modified

- `backend/tests/integration/test_job_orchestration.py` - Job lifecycle tests
- `backend/tests/integration/test_job_retry_scenarios.py` - Retry tests
- Test fixtures for database, mocks, etc.

## Decisions Made

[Integration test strategy, mocking approach, database setup]

## Issues Encountered

[Database cleanup issues, timing issues, mock challenges]

## Next Step

Ready for 10-03-PLAN.md (Documentation)
</output>
